---
title: "Economic Clustering Summary Report: Uganda 2016 (CC #8)"
author: "Andy Kim"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  word_document:
    reference_docx: "summaryscript_style.docx"

always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T)
```

```{r install-packages, message=F, warning=F}
library(tidyverse)
library(parallelDist)
library(haven)
library(knitr)
library(kableExtra)
library(gdtools)
```


```{r user-functions, eval = F}
# Functions (run these)
top_clus_table <- function(asw_mat, n){
  mat <- asw_mat %>% 
    arrange(desc(ASW)) %>%
    dplyr::slice(1:n)
  
  mat2 <- select(mat,-c(ASW))
  
  #note: need to change 4 if diff number of variables used
  new_mat <- matrix(data = NA, nrow = n, ncol = 4)
  
  names <- colnames(mat2)
  
  for(i in 1:nrow(mat)){
    new_mat[i,] <- names[which(!is.na(mat2[i,]))]
  }
  
  mat3 <- as.data.frame(cbind(mat[,1],new_mat))
  
  return(mat3)
}
print_proptable <- function(proptable){
  if(length(proptable) == 2){
    labels <- names(proptable)
    values <- proptable
    
    value1 <- values[grepl("1", labels)] %>% 
      round(3) %>% 
      `*`(100)
    
    paste0("Binary, ", value1, "% 1s (or yes)")
  } else if(length(proptable) > 8){
    #labels <- names(proptable)
    values <- proptable
    
    paste0("Binary, Mode: ", names(which.max(values)))
  }
  else{
    labels <- names(proptable)
    values <- proptable %>% 
      round(3) %>% 
      `*`(100)
    
    l_v <- data.frame(values)
    f_labels <- paste0(0:(length(labels) - 1), " (", l_v[,1], ")") # attaching factors
    f_v_labels <- paste0(f_labels, " = ", values, "%", collapse = ", \n " )
    
    paste0("Categorical, ", f_v_labels)
  }
}
clus_config <- function(data, i, tab, nCores){
  vars <- as.vector(as.matrix(tab[i,2:5]))
  labels <- plyr::mapvalues(vars,
                            from = var_to_label_df$rowname,
                            to = var_to_label_df$V1, 
                            warn_missing = F)
  
  subset_data <- data %>% select("wt", vars) 
  
  out <- clusNode(subset_data,4,nCores)
  subset_data$node <- out[[1]]$clustering %>% 
    unlist() %>% 
    as.character() %>% 
    as.factor() %>% 
    as.numeric()
  
  rel_prop <- as.matrix(table(subset_data$node)/nrow(subset_data)) %>% 
    as.data.frame() %>% 
    rownames_to_column() %>%
    `colnames<-`(c("node", "prop"))
  
  grouped <- subset_data %>% 
    unite(clus, c(vars), remove = F) %>% 
    group_by(clus) %>%
    summarise(node = unique(node),
              var1 = first(!!as.name(vars[1])),
              var2 = first(!!as.name(vars[2])),
              var3 = first(!!as.name(vars[3])),
              var4 = first(!!as.name(vars[4]))) %>% 
    arrange(node) %>% 
    select(!clus) %>% 
    merge(rel_prop) %>% 
    mutate(prop = round(prop*100, 2)) %>% 
    mutate(prop = replace(prop, duplicated(prop), NA))
  
  colnames(grouped) <- c("Cluster Group", labels, "Proportion (%)")
  
  return(grouped)
}
clusNode <- function(data, num.in.cluster, ncores){
  
  ASW<-vector()
  combi<-list()
  parD<-list()
  wcKMR<-list()
  
  if (class(unlist(data[,1]))=="numeric"){
    wt<-unlist(data[,1])
    data<-data[,-1]
  } else {
    wt<-rep(1, nrow(data))
  }
  
  p <- ncol(data)
  col_cat<-seq(1,p,1)
  combn<-utils::combn(c(1:p),num.in.cluster)
  col_indx=matrix(c("NULL"), ncol(combn), p, byrow=FALSE)
  for (i in 1:ncol(combn)){
    col_indx[i,]<- t(is.element(col_cat, combn[,i]))
    col_indx[i,][col_indx[i,]==FALSE]<- NA
    colnames(col_indx)=colnames(data)
  }
  
  combi<-data[,!is.na(col_indx[i,])]
  combi_mat<-data.matrix(combi)
  parD<-parDist(combi_mat, method =  "hamming", threads = ncores) 
  wcKMR<-WeightedCluster::wcKMedRange(parD, kvals=(5), weights=wt)
  return(list(wcKMR,combi_mat))
}
```

```{r, warning = F}
#### Remember to change the title of the document to reflect the correct Country + Year
# Change country-year here
# e.g. AO11 BF1718 BN1718 BU1617 CD1314 CM18 ET19 GA12 GH19 GM1920 GN18 KM12 SL19 SN19 TZ17 ZA16
source("./input_files/EC_user_functions.R")
#########
cy <- "UG16"
num_var <- 4 # number of variables used to generate clusters
num_cluster <- 5
index <- 8
nCores <- parallel::detectCores()

# Change paths to DHS files here
hh_path <- "./data/dhs/Uganda_2016/UGHR7BDT/UGHR7BFL.DTA"
ind_path <- "./data/dhs/Uganda_2016/UGIR7BDT/UGIR7BFL.DTA"
#tablepng_path <- "../summoutput_files/"
#########

# Path to the cleaned DHS file
dhspath <- paste0("./data/cleaned/", cy, "_clean.rds")

# Path to the ASW output file (updated)
#aswpath <- paste0("../asw_files/", cy, "_ASW_", num_var, "cluster.rds")
aswpath <- paste0("./data/asw/ASW_", cy, "_", num_var, "cluster.rds")

dhs <- readRDS(dhspath)
asw_mat <- readRDS(aswpath) # %>% dplyr::select(-X)

# Assign missing labels to multicat variables
for(i in 1:length(Hmisc::label(dhs))){
  if(Hmisc::label(dhs)[i] == ""){
    Hmisc::label(dhs[[i]]) <- names(dhs)[i]
  }
}

# Create dictionary of labels to variable names
var_to_label_df <- data.frame(lapply(dhs, attr, "label")) %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column()

#dhs %>% filter_all(any_vars(. == 9))
```

# Summary of Data

```{r, eval = F}
paste0("Country Code-year: ", cy)
paste0("Number of observations: ", nrow(dhs))
paste0("Number of clusters: ", num_cluster)
paste0("Number of variables used: ", ncol(dhs) - 1)
paste0("Distance used: Hamming")
paste0("Variables used in the algorithm: ", paste0(names(dhs)[-1], collapse = ", "))
```
**Country Code-year:** `r cy`

**Number of observations:** `r nrow(dhs)`

**Number of clusters:** `r num_cluster`

**Number of variables used:** `r ncol(dhs) - 1`

**Distance used:** Hamming

**Variables used in the algorithm:** `r paste0(names(dhs)[-1], collapse = ", ")`

#
\pagebreak

# Top Variable Groupings (Sorted by ASW)

```{r top-cluster}
## Top cluster table
tab1 <- top_clus_table(asw_mat, 10)

# Create ASW dataframe using labels, not var names
tab1_labs <- apply(tab1[,2:5], 2, function(x){
  plyr::mapvalues(x, from = var_to_label_df$rowname, to = var_to_label_df$V1, warn_missing = F)
})

tab1_asw <- round(as.numeric(tab1[,1]),4)
tab1_clean <- cbind(c(1:length(tab1_asw)), tab1_asw, tab1_labs) %>% 
  `colnames<-`(c("Group", "ASW", "Var. 1", "Var. 2", "Var. 3", "Var. 4"))

# knitr::kable(tab1_clean, booktabs = T) %>%
#   kable_styling(full_width = T) %>% 
#   row_spec(1:nrow(tab1_clean), hline_after = T) %>% 
#   column_spec(1, "1cm")


tab1_clean.f <- tab1_clean %>% 
  as.data.frame() %>% 
  flextable::flextable() %>% 
  flextable::autofit() %>% 
  flextable::set_table_properties(layout = "autofit")

knitr::knit_print(tab1_clean.f)
```

#
\pagebreak

# Marginal Distributions

```{r}
##### Marginal Distributions 
unq.vars <- unique(as.vector(as.matrix(tab1[,-1])))

props <- subset(dhs, select = unq.vars) %>% 
  lapply(table) %>% 
  lapply(prop.table) %>% 
  lapply(print_proptable) %>% 
  as.data.frame() %>% t()

descs <- lapply(dhs, attr, "label")[unq.vars] %>% unlist()

props_top_unsorted <- table(unlist(tab1[,-1]))*10
props_top_sorted <- paste0(props_top_unsorted[match(unq.vars, names(props_top_unsorted))], "%")

marg_dist_table <- cbind(unq.vars, descs, props_top_sorted, props) %>% data.frame()
names(marg_dist_table) <- c("Variable", "Description", "% Time in Top Clusters", "Distribution")
rownames(marg_dist_table) = NULL


# knitr::kable(marg_dist_table, booktabs = T) %>%
#   kable_styling(full_width = T) %>% 
#   row_spec(1:nrow(marg_dist_table), hline_after = T) %>% 
#   column_spec(1, "1cm")
marg_dist_table.f <- marg_dist_table %>% 
  as.data.frame() %>% 
  flextable::flextable() %>% 
  flextable::autofit() %>% 
  flextable::set_table_properties(layout = "autofit")

knitr::knit_print(marg_dist_table.f)
```

```{r, warning=FALSE}
#### Cluster Configurations
cc_out <- clus_config(data = dhs, i=index, tab=tab1, nCores = nCores)
group1 <- cc_out[[1]]
```

#
\pagebreak

# Cluster Configuration

```{r, warning=FALSE}
options(knitr.kable.NA = '')
# knitr::kable(group1, booktabs = T) %>%
#   kable_styling(full_width = T) %>% 
#   row_spec(1:nrow(group1), hline_after = T) %>% 
#   column_spec(1, "1cm")
group1.f <- group1 %>% 
  as.data.frame() %>% 
  flextable::flextable() %>% 
  flextable::autofit() %>% 
  flextable::set_table_properties(layout = "autofit")

knitr::knit_print(group1.f)
```


#
\pagebreak

# Validation Tables

```{r, warning=F, message=F, results='hide'}
source("./input_files/EC_user_functions.R")

# select variable set
vars <- unlist(as.vector(tab1[index,-1]))

# load in raw datasets
ind <- haven::read_dta(ind_path) 

hh <- haven::read_dta(hh_path) %>% 
  mutate(wt = ifelse(hv012 == 0, hv013, hv012)*hv005/1e+06) %>% 
  preprocess_dhsfactors_adj()

ind_vars <- c("v001", "v002", "v005")

if(c("v149") %in% names(ind)){
  ind_vars <- c(ind_vars, "v149")
}

if(all(c("v201", "v206", "v207") %in% names(ind))){
  ind$deceas = ifelse(!is.na((ind$v206+ind$v207)/ind$v201), (ind$v206+ind$v207)/ind$v201, 0)
  ind$de_cat = cut(ind$deceas, 
                 breaks = c(-0.01,0.00001,0.3399,0.6699,1),
                 labels = c("0%", "1-33%", "34-66%", "67+%"))
  ind_vars <- c(ind_vars, "deceas", "de_cat")
}

if(all(c("v326") %in% names(ind))){
  ind$health = ind$v326 %>%
    str_replace_all('1[0-9]', '0') %>%
    str_replace_all('2[0-9]', '1') %>%
    str_replace_all('3[0-9]', '1') %>%
    str_replace_all('4[0-9]', '2') %>%
    str_replace_all('9[0-9]', '2')
  ind_vars <- c(ind_vars, "health")
}

ind_subset <- ind %>%
  dplyr::select(all_of(ind_vars))

# CHECK IF NROW OF HH_SUBSET MATCHES NROW OF DHS. If not, filter aas done here
hh_subset <- hh %>%
  dplyr::filter(hv237 != 8,
                sh125 != 8,
                sh144b != 8) %>% 
  dplyr::select(hv001, hv002, wt, all_of(unq.vars)) #normally v106 is ha66_01

# re-generate clustering IDs for each HH
# out <- clusNode(select(hh_subset, wt, all_of(vars)), 4, ncores = 8)
# hh_subset$id <- out[[1]]$clustering %>% 
#   unlist() %>% 
#   as.factor() %>% 
#   as.numeric()

hh_subset$id <- cc_out[[2]]

# Merge the datasets
merged_data <- merge(hh_subset, ind_subset, 
                     by.x=c("hv001", "hv002"), 
                     by.y=c("v001", "v002"), all.y=FALSE)
```


```{r, warning=F, message=F, results='hide'}

if(all(c("de_cat") %in% names(merged_data))){
  dectab <- merged_data %>%
    tabyl(id, de_cat, show_missing_levels = FALSE, show_na = FALSE)

  ordered_decid <- cbind(dectab[,1],prop.table(as.matrix(dectab[,2:5]), 1)) %>% 
    as.data.frame() %>% 
    arrange(desc(`0%`)) %>% 
    select(V1) %>% 
    unlist()
  
  dectab <- dectab[match(ordered_decid, dectab$id),]
  
  dectab2 <- cbind(dectab[,1:2], rowSums(dectab[,3:5])) %>% 
  `colnames<-`(c("id", "0%", ">0%"))

  ordered_decid2 <- cbind(dectab2[,1],prop.table(as.matrix(dectab2[,2:3]), 1)) %>% 
    as.data.frame() %>% 
    arrange(desc(`0%`)) %>% 
    select(V1) %>% 
    unlist()
  
  dectab2 <- dectab2[match(ordered_decid2, dectab2$id),]
}

if(all(c("v149") %in% names(merged_data))){
  edutab <- merged_data %>%
    tabyl(id, v149, show_missing_levels = FALSE, show_na = FALSE)

  # Sorted by weighted average across each row
  ordered_eduid <- cbind(c(1:5), prop.table(as.matrix(edutab[,2:7]), 1) %*% diag(c(0:5)) %>% rowSums()) %>% 
    as.data.frame() %>% 
    arrange(desc(V2))
  
  edutab <- edutab[match(ordered_eduid$V1, edutab$id),]
}

if(all(c("health") %in% names(merged_data))){
  pritab <- merged_data %>%
   tabyl(id, health, show_missing_levels = FALSE, show_na = FALSE)
  
  ordered_priid <- cbind(pritab[,1],prop.table(as.matrix(pritab[,2:4]), 1)) %>% 
    as.data.frame() %>% 
    arrange(`0`) %>% 
    select(V1) %>% 
    unlist()
  
  pritab <- pritab[match(ordered_priid, pritab$id),]
}


```

## a.1) Using Children Deceased (Sorted by proportion of 0%)


```{r, warning=F, message=F}
if(exists("dectab")){
  dectab.f <- dectab %>%
  adorn_totals(where = "row") %>%
  adorn_percentages(denominator = "row") %>%
  adorn_pct_formatting() %>% 
  adorn_ns(position = "front") %>%
  adorn_title(
    row_name = "Cluster ID",
    col_name = "Children Deceased",
    placement = "combined") %>%
  flextable::flextable() %>% 
  flextable::footnote(i = 1, j = 1,
           ref_symbols = "*",
           value = as_paragraph(paste("The chi-squared p-value is", 
                                      round(chisq.test(dectab)$p.val,4)))) %>%
  flextable::autofit() %>% 
  flextable::set_table_properties(layout = "autofit")

knitr::knit_print(dectab.f)
}


```

## a.2) Aggregating proportions greater than 0%

\newline

```{r, warning=F, message=F}
if(exists("dectab2")){
  dectab2.f <- dectab2 %>%
    adorn_totals(where = "row") %>%
    adorn_percentages(denominator = "row") %>%
    adorn_pct_formatting() %>% 
    adorn_ns(position = "front") %>%
    adorn_title(
      row_name = "Cluster ID",
      col_name = "Children Deceased",
      placement = "combined") %>%
    flextable::flextable() %>% 
    flextable::footnote(i = 1, j = 1,
             ref_symbols = "*",
             value = as_paragraph(paste("The chi-squared p-value is", 
                                        round(chisq.test(dectab2)$p.val,4)))) %>%
    flextable::autofit()  %>% 
    flextable::set_table_properties(layout = "autofit")
  
  knitr::knit_print(dectab2.f)
}
```

#
\pagebreak

## b) Using Individual Education Level Attained (Sorted by weighted average by row)

\newline

```{r, warning=F, message=F}
if(exists("edutab")){
  edutab.f <- edutab %>%
    adorn_totals(where = "row") %>%
    adorn_percentages(denominator = "row") %>%
    adorn_pct_formatting() %>% 
    adorn_ns(position = "front") %>%
    adorn_title(
      row_name = "Cluster ID",
      col_name = "Education",
      placement = "combined") %>% 
    mutate(`W. Avg.` = round(c(ordered_eduid$V2, 
                         sum(prop.table(as.matrix(colSums(edutab[,2:7]),1)) * 0:5)),2)) %>%
    flextable::flextable() %>% 
    flextable::footnote(i = 1, j = 1, ref_symbols = "*",
                        value = as_paragraph(paste("The chi-squared p-value is",
                                        round(wtd.chi.sq(merged_data$id,
                                                         merged_data$v149,
                                                         weight = merged_data$v005)[3],4)))) %>%
    flextable::footnote(i = 1, j = 1, ref_symbols = "a",
                        value = as_paragraph(paste("0=none,1=incomplete primary, 2=primary, 3=incomplete secondary, 4=secondary, 5=higher"))) %>% 
    flextable::autofit() %>% 
    flextable::set_table_properties(layout = "autofit")
  
  knitr::knit_print(edutab.f)
}
```

#
\pagebreak

## c) Using Primary Healthcare Source (Sorted by % enrolled in public healthcare [ascending order])

\newline


```{r, warning=F, message=F}
if(exists("pritab")){
  pritab.f <- pritab %>%
    adorn_totals(where = "row") %>%
    adorn_percentages(denominator = "row") %>%
    adorn_pct_formatting() %>% 
    adorn_ns(position = "front") %>%
    adorn_title(
      row_name = "Cluster ID",
      col_name = "Primary Healthcare Source",
      placement = "combined") %>%
    flextable::flextable() %>%
    footnote(i = 1, j = 1,
             ref_symbols = "*",
             value = as_paragraph(paste("The chi-squared p-value is",
                                        round(chisq.test(pritab)$p.val,4)))) %>%
    footnote(i = 1, j = 1,
             ref_symbols = "a",
             value = as_paragraph(paste("0=public/government, 1=private, 2=other"))) %>% 
    flextable::autofit() %>% 
    flextable::set_table_properties(layout = "autofit")
  
  knitr::knit_print(pritab.f)
}
```

\pagebreak

# Ordered Logisitic Regression Analysis

```{r, warning=F}
###### Functions
clus_config_ordered <- function(data, i, tab, nCores){
  
  ##### Extract the variables from clustering i
  ##### and get the cluster distribution in the data
  vars <- as.vector(as.matrix(tab[i,2:5]))
  sub_data <- data %>% dplyr::select("wt", vars)
  names <- colnames(sub_data)[-1]
  out <- clusNode(sub_data,4,nCores)
  
  #medoids
  #out[[2]][as.numeric(c(names(table(clusters$cluster5)))),]
  
  ##### Add the encodings of the clusters and node values
  sub_data$clus <- paste0(unname(unlist(sub_data[,c(tab[i,2])])), 
                      unname(unlist(sub_data[,c(tab[i,3])])),
                      unname(unlist(sub_data[,c(tab[i,4])])),
                      unname(unlist(sub_data[,c(tab[i,5])]))
  )
  sub_data$node <- out[[1]]$clustering %>% unlist()
  
  ##### Create summary data of each cluster node
  grouped <- sub_data %>% group_by(node) %>% 
    group_by(clus) %>%
    summarise(node = unique(node),
              var1 = first(!!as.name(names[1])),
              var2 = first(!!as.name(names[2])),
              var3 = first(!!as.name(names[3])),
              var4 = first(!!as.name(names[4])))
  grouped$node <- as.numeric(as.factor(as.character(grouped$node)))
  colnames(grouped) <- c("clus","node", names)
  grouped$prop <- prop.table(table(sub_data$clus))*100
  
  return(grouped)
}
```

```{r, warning=F}
##### Run the cluster configuration function
##### Take note of what you set as i, as this will correspond 
##### To the variables you're analyzing from the top cluster results
i <- 1
grouped <- clus_config_ordered(data = dhs, i=i, tab=tab1, nCores = nCores)

##### At this point, take note of if any of the variables used are not binary
##### If so, they should be releveled and made into numeric variables as appropriate
##### Map the variables to a numbered value ranging between 0 and 1
##### For example, roof has levels (rudimentary, other, natural, finished)
##### We could map this to (0,1,1,1) if we wanted to view rudimentary as "not having a roof"
##### Or, we could map to (0,0,0.5,1) if we viewed finished as more of an asset than a natural roof
##### In the following comment is a code example of how you'd change this for roof:
##### grouped$roof <- dplyr::recode(grouped$roof, "rudimentary" = 0, "other" = 0, "natural" = 0.5, "finished" = 1)

##### Now, we count the average number of assets of each node in the cluster
grouped$assets <- apply(grouped %>% dplyr::select(-c(clus,node,prop)), MARGIN = 1, sum)
grouped_meta <- grouped %>% group_by(node) %>% 
  summarise(ave_asset = mean(assets),
            min_asset = min(assets),
            max_asset = max(assets),
            tot_prop = sum(prop)/100
            )

##### Create the rank variable, which gives the highest value to the most asset heavy
##### groups, and the lowest value to the least asset heavy
grouped_meta$rank <- rank(grouped_meta$ave_asset)

##### Check for inequalities in the rank to get the cluster scoring
##### The score is defined as the proportion of the population that 
##### You'd need to re-rank to break any ties in the asset-scoring
##### So if two clusters have the same rank, we could break this tie
##### By reordering them and moving the smallest proportion cluster

score <- 0
if(length(unique(grouped_meta$rank)) != nrow(grouped_meta)){
  for(r in unique(grouped_meta$rank)){
    tmp <- grouped_meta %>% filter(rank == r)
    if(nrow(tmp) > 1){
      score <- score + sum(tmp$tot_prop) - max(tmp$tot_prop)
    }
  }
}

##### A final cleaned grouped dataset with summary data
group_final <- merge(grouped, grouped_meta, by = "node")
```

```{r, warning=F, message=F, results='hide'}
##### Use "merged_data" combining household and individual data
##### As loaded in an above code chunk

##### NOTE: if you had to recode a non-binary variable like roof
##### You should replace it here with the categorical coding to run this smoothly
#####
##### Here is where you'd reinstate the roof variable with its categorical values
##### Make sure to add it to the "hh" dataset as seen above
##### hh$roof <- dhs$roof
##### Then, you'd need to remerge the data

##### Get clustering value to merge for ordinal logistic data
merged_data$clus <- paste0(unname(unlist(merged_data[,c(tab1[i,2])])), 
                      unname(unlist(merged_data[,c(tab1[i,3])])),
                      unname(unlist(merged_data[,c(tab1[i,4])])),
                      unname(unlist(merged_data[,c(tab1[i,5])]))
)

ord_log_data <- merge(merged_data,group_final[,c("clus","rank")],by="clus")
```

## Ordered Logistic Using ordinal::clm

This implements a Test of Trend and extracts the p-values for the validation variables. The p-values come from a one-sided hypothesis test that the coefficient of the rank in the model is positive, so that as the rank increases (become more asset heavy) the validation variable increases (assuming its values imply increasing wealth/SES).

```{r, warning=F}
library(ordinal)
##### May need to modify outcome variables where appropriate

##### Reorder de_cat variable so that worst outcome is lowest
##### Need 0 = 67+%, 1 = 34-66%, etc...
ord_log_data$de_cat <- factor(ord_log_data$de_cat, levels = c("67+%","34-66%","1-33%","0%"))
ord_log_decat <- clm(de_cat ~ rank, data = ord_log_data)
res_decat <- summary(ord_log_decat)

##### No reordering needs to occur with education
ord_log_educ <- clm(factor(v149) ~ rank, data = ord_log_data)
res_educ <- summary(ord_log_educ)

##### Healthcare variable does not exist

##### Let H1 be the alternative hypothesis
##### For H1: beta < 0 set lower = TRUE, for H1: beta > 0, set lower = FALSE
p_decat <- pt(coef(res_decat)["rank",3], ord_log_decat$df, lower = FALSE)
p_educ <- pt(coef(res_educ)["rank",3], ord_log_educ$df, lower = FALSE)
```

**Cluster scoring:** `r score`

**Ordinal Logistic Regression P-values**

**P-value for Proportion of Children Deceased** `r p_decat`

**P-value for Educational Attainment** `r p_educ`
