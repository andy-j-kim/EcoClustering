\pagebreak

## Ordered Logistic Using ordinal::clm

This implements a Test of Trend and extracts the p-values for the validation variables. The p-values come from a one-sided hypothesis test that the coefficient of the rank in the model is positive, so that as the rank increases (become more asset heavy) the validation variable increases (assuming its values imply increasing wealth/SES).


```{r}
###### Functions
ord_log_fxn <- function(data, i, tab, nCores, merged_dhs){
  
  ##### Extract the variables from clustering i
  ##### and get the cluster distribution in the data
  #vars <- as.vector(as.matrix(tab[i,3:6])) 
  vars <- dhs_labels$dhs_code[which(dhs_labels$dhs_label %in% as.vector(as.matrix(tab[i,3:6])))]
  sub_data <- data %>% dplyr::select("wt", vars)
  names <- colnames(sub_data)[-1]
  out <- find_cluster_id(sub_data,num_var,num_cluster,nCores)
  
  #medoids
  #out[[2]][as.numeric(c(names(table(clusters$cluster5)))),]
  
  ##### Add the encodings of the clusters and node values
  sub_data$clus <- paste0(unname(unlist(sub_data[,vars[1]])), 
                      unname(unlist(sub_data[,vars[2]])),
                      unname(unlist(sub_data[,vars[3]])),
                      unname(unlist(sub_data[,vars[4]]))
  )
  sub_data$node <- out
  
  ##### Create summary data of each cluster node
  grouped <- sub_data %>% group_by(node) %>% 
    group_by(clus) %>%
    summarise(node = unique(node),
              var1 = first(!!as.name(names[1])),
              var2 = first(!!as.name(names[2])),
              var3 = first(!!as.name(names[3])),
              var4 = first(!!as.name(names[4])))
  grouped$node <- as.numeric(as.factor(as.character(grouped$node)))
  colnames(grouped) <- c("clus","node", names)
  grouped$prop <- prop.table(table(sub_data$clus))*100
  
  ##### Run the cluster configuration function
  ##### Take note of what you set as i, as this will correspond 
  ##### To the variables you're analyzing from the top cluster results
  grouped <- clus_config_ordered(data = dhs, i=i, tab=top_varset_table, nCores = nCores)

  ##### At this point, take note of if any of the variables used are not binary
  ##### If so, they should be releveled and made into numeric variables as appropriate
  ##### Map the variables to a numbered value ranging between 0 and 1
  ##### For example, roof has levels (rudimentary, other, natural, finished)
  ##### We could map this to (0,1,1,1) if we wanted to view rudimentary as "not having a roof"
  ##### Or, we could map to (0,0,0.5,1) if we viewed finished as more of an asset than a natural roof
  ##### In the following comment is a code example of how you'd change this for roof:
  ##### grouped$roof <- dplyr::recode(grouped$roof, "rudimentary" = 0, "other" = 0, "natural" = 0.5, "finished" = 1)

  ##### Now, we count the average number of assets of each node in the cluster
  grouped$assets <- apply(grouped %>% dplyr::select(-c(clus,node,prop)), MARGIN = 1, sum)
  grouped_meta <- grouped %>% group_by(node) %>% 
    summarise(ave_asset = mean(assets),
              min_asset = min(assets),
              max_asset = max(assets),
              tot_prop = sum(prop)/100
              )

  ##### Create the rank variable, which gives the highest value to the most asset heavy
  ##### groups, and the lowest value to the least asset heavy
  grouped_meta$rank <- rank(grouped_meta$ave_asset)

  ##### Check for inequalities in the rank to get the cluster scoring
  ##### The score is defined as the proportion of the population that 
  ##### You'd need to re-rank to break any ties in the asset-scoring
  ##### So if two clusters have the same rank, we could break this tie
  ##### By reordering them and moving the smallest proportion cluster

  score <- 0
  if(length(unique(grouped_meta$rank)) != nrow(grouped_meta)){
    for(r in unique(grouped_meta$rank)){
      tmp <- grouped_meta %>% filter(rank == r)
      if(nrow(tmp) > 1){
        score <- score + sum(tmp$tot_prop) - max(tmp$tot_prop)
      }
   }
  }

  print(paste0("Evaluation score",score))
  ##### A final cleaned grouped dataset with summary data
  group_final <- merge(grouped, grouped_meta, by = "node")
  
  ##### Use "merged_data" combining household and individual data
  ##### As loaded in an above code chunk

  ##### NOTE: if you had to recode a non-binary variable like roof
  ##### You should replace it here with the categorical coding to run this smoothly
  #####
  ##### Here is where you'd reinstate the roof variable with its categorical values
  ##### Make sure to add it to the "hh" dataset as seen above
  ##### hh$roof <- dhs$roof
  ##### Then, you'd need to remerge the data

  ##### Get clustering value to merge for ordinal logistic data
  vars <- dhs_labels$dhs_code[which(dhs_labels$dhs_label %in% as.vector(as.matrix(tab[i,3:6])))]

  merged_dhs$clus <- paste0(unname(unlist(merged_dhs[,vars[1]])), 
                        unname(unlist(merged_dhs[,vars[2]])),
                        unname(unlist(merged_dhs[,vars[3]])),
                        unname(unlist(merged_dhs[,vars[4]]))
  )

  ord_log_data <- merge(merged_dhs,group_final[,c("clus","rank")],by="clus")
  return(ord_log_data)
}

ord_log_analysis <- function(ord_log_data){
  library(ordinal)
  ##### May need to modify outcome variables where appropriate

  ##### Reorder de_cat variable so that worst outcome is lowest
  ##### Need 0 = 67+%, 1 = 34-66%, etc...
  ord_log_data$de_cat <- factor(ord_log_data$de_cat, levels = c("67+%","34-66%","1-33%","0%"))
  ord_log_decat <- clm(de_cat ~ rank, data = ord_log_data)
  res_decat <- summary(ord_log_decat)

  ##### No reordering needs to occur with education
  ord_log_educ <- clm(factor(v149) ~ rank, data = ord_log_data)
  res_educ <- summary(ord_log_educ)

  ##### Need to remove 2 = "other" observations from health analysis
  ##### 0 = public, 1 = private
  ord_log_subset_health <- ord_log_data %>% filter(health != 2)
  ord_log_health <- clm(factor(health) ~ rank, data = ord_log_subset_health)
  res_health <- summary(ord_log_health)

  ##### Let H1 be the alternative hypothesis
  ##### For H1: beta < 0 set lower = TRUE, for H1: beta > 0, set lower = FALSE
  p_decat <- pt(coef(res_decat)["rank",3], ord_log_decat$df, lower = FALSE)
  p_educ <- pt(coef(res_educ)["rank",3], ord_log_educ$df, lower = FALSE)
  p_health <- pt(coef(res_health)["rank",3], ord_log_health$df, lower = FALSE)
  
  res <- as.data.frame(rbind(summary(ord_log_decat)$coefficients["rank",c("Estimate","Std. Error")] %>% unname(),
        summary(ord_log_educ)$coefficients["rank",c("Estimate","Std. Error")] %>% unname(),
        summary(ord_log_health)$coefficients["rank",c("Estimate","Std. Error")] %>% unname()))
  
  colnames(res) <- c("logOR","se(logOR)")
  res$var <- c("Mortality","Education","Health")
  
  print(res)
  }
```

```{r}
ord_log_data <- ord_log_fxn(data = dhs, i=1, tab=top_varset_table, 
                                    nCores = nCores, merged_dhs=merged_dhs)

ord_log_analysis(ord_log_data)
```
